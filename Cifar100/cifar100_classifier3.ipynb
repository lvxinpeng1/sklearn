{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR100-Classification3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置基本参数\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "#learning_rate = 0.02\n",
    "num_epochs = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据标准化\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]),\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保持网络畅通，这个下载挺快的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR100\n",
      "    Number of datapoints: 50000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "#在线下载数据\n",
    "data_sets = {\n",
    "    'train': torchvision.datasets.CIFAR100(root='data', train=True, download=True, transform=data_transforms['train']),\n",
    "    'test': torchvision.datasets.CIFAR100(root='data', download=True, transform=data_transforms['test'])\n",
    "}\n",
    "#查看数据信息\n",
    "print(data_sets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据到torch中，训练集使用shuffle\n",
    "dataloaders = {\n",
    "    'train':\n",
    "    torch.utils.data.DataLoader(data_sets['train'],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0),\n",
    "    'test':\n",
    "    torch.utils.data.DataLoader(data_sets['test'],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#检查GPU是否可用\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#准备网络模型，使用的是resnet50，可以在线下载模型\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "model = model.cuda() if use_cuda else model\n",
    "    \n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 1024)\n",
    "model.fc = nn.Sequential(\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(num_ftrs, 1024),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(1024, 512),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(128, len(data_sets['train'].classes))\n",
    ")\n",
    "\n",
    "model.fc = model.fc.cuda() if use_cuda else model.fc\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (4): Dropout(p=0.2, inplace=False)\n",
       "    (5): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (6): Dropout(p=0.2, inplace=False)\n",
       "    (7): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\n",
      "Epoch [0/15], Step [0/782], Loss: 4.6158\n",
      "Epoch [0/15], Step [20/782], Loss: 4.6153\n",
      "Epoch [0/15], Step [40/782], Loss: 4.6248\n",
      "Epoch [0/15], Step [60/782], Loss: 4.5515\n",
      "Epoch [0/15], Step [80/782], Loss: 4.3367\n",
      "Epoch [0/15], Step [100/782], Loss: 4.0509\n",
      "Epoch [0/15], Step [120/782], Loss: 4.0236\n",
      "Epoch [0/15], Step [140/782], Loss: 3.8641\n",
      "Epoch [0/15], Step [160/782], Loss: 3.7379\n",
      "Epoch [0/15], Step [180/782], Loss: 3.1923\n",
      "Epoch [0/15], Step [200/782], Loss: 3.2778\n",
      "Epoch [0/15], Step [220/782], Loss: 3.1392\n",
      "Epoch [0/15], Step [240/782], Loss: 3.3162\n",
      "Epoch [0/15], Step [260/782], Loss: 3.3497\n",
      "Epoch [0/15], Step [280/782], Loss: 2.9117\n",
      "Epoch [0/15], Step [300/782], Loss: 3.3305\n",
      "Epoch [0/15], Step [320/782], Loss: 3.2646\n",
      "Epoch [0/15], Step [340/782], Loss: 3.0170\n",
      "Epoch [0/15], Step [360/782], Loss: 2.7164\n",
      "Epoch [0/15], Step [380/782], Loss: 2.7460\n",
      "Epoch [0/15], Step [400/782], Loss: 3.2040\n",
      "Epoch [0/15], Step [420/782], Loss: 2.8882\n",
      "Epoch [0/15], Step [440/782], Loss: 2.8224\n",
      "Epoch [0/15], Step [460/782], Loss: 2.6083\n",
      "Epoch [0/15], Step [480/782], Loss: 2.9192\n",
      "Epoch [0/15], Step [500/782], Loss: 3.1873\n",
      "Epoch [0/15], Step [520/782], Loss: 2.8488\n",
      "Epoch [0/15], Step [540/782], Loss: 2.8485\n",
      "Epoch [0/15], Step [560/782], Loss: 3.0769\n",
      "Epoch [0/15], Step [580/782], Loss: 2.5440\n",
      "Epoch [0/15], Step [600/782], Loss: 2.5723\n",
      "Epoch [0/15], Step [620/782], Loss: 2.7806\n",
      "Epoch [0/15], Step [640/782], Loss: 2.7336\n",
      "Epoch [0/15], Step [660/782], Loss: 2.8605\n",
      "Epoch [0/15], Step [680/782], Loss: 2.7068\n",
      "Epoch [0/15], Step [700/782], Loss: 2.3778\n",
      "Epoch [0/15], Step [720/782], Loss: 2.7280\n",
      "Epoch [0/15], Step [740/782], Loss: 2.5727\n",
      "Epoch [0/15], Step [760/782], Loss: 2.5812\n",
      "Epoch [0/15], Step [780/782], Loss: 2.2719\n",
      "\n",
      "train-loss: 0.0503, train-acc: 21.9380\n",
      "test loss: 0.0372, test acc: 38.1240\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 1\n",
      "\n",
      "Epoch [1/15], Step [0/782], Loss: 2.3094\n",
      "Epoch [1/15], Step [20/782], Loss: 2.4952\n",
      "Epoch [1/15], Step [40/782], Loss: 2.5598\n",
      "Epoch [1/15], Step [60/782], Loss: 2.4225\n",
      "Epoch [1/15], Step [80/782], Loss: 2.4937\n",
      "Epoch [1/15], Step [100/782], Loss: 2.6725\n",
      "Epoch [1/15], Step [120/782], Loss: 2.8113\n",
      "Epoch [1/15], Step [140/782], Loss: 2.1769\n",
      "Epoch [1/15], Step [160/782], Loss: 2.2911\n",
      "Epoch [1/15], Step [180/782], Loss: 2.6728\n",
      "Epoch [1/15], Step [200/782], Loss: 2.3562\n",
      "Epoch [1/15], Step [220/782], Loss: 1.8928\n",
      "Epoch [1/15], Step [240/782], Loss: 2.4741\n",
      "Epoch [1/15], Step [260/782], Loss: 2.1261\n",
      "Epoch [1/15], Step [280/782], Loss: 2.0934\n",
      "Epoch [1/15], Step [300/782], Loss: 2.5026\n",
      "Epoch [1/15], Step [320/782], Loss: 2.5892\n",
      "Epoch [1/15], Step [340/782], Loss: 2.6186\n",
      "Epoch [1/15], Step [360/782], Loss: 2.6553\n",
      "Epoch [1/15], Step [380/782], Loss: 2.1739\n",
      "Epoch [1/15], Step [400/782], Loss: 2.3122\n",
      "Epoch [1/15], Step [420/782], Loss: 2.4355\n",
      "Epoch [1/15], Step [440/782], Loss: 2.3494\n",
      "Epoch [1/15], Step [460/782], Loss: 2.3533\n",
      "Epoch [1/15], Step [480/782], Loss: 2.3077\n",
      "Epoch [1/15], Step [500/782], Loss: 1.7917\n",
      "Epoch [1/15], Step [520/782], Loss: 2.3768\n",
      "Epoch [1/15], Step [540/782], Loss: 2.2528\n",
      "Epoch [1/15], Step [560/782], Loss: 2.2396\n",
      "Epoch [1/15], Step [580/782], Loss: 2.0971\n",
      "Epoch [1/15], Step [600/782], Loss: 2.9757\n",
      "Epoch [1/15], Step [620/782], Loss: 1.8252\n",
      "Epoch [1/15], Step [640/782], Loss: 2.5122\n",
      "Epoch [1/15], Step [660/782], Loss: 2.3021\n",
      "Epoch [1/15], Step [680/782], Loss: 2.1499\n",
      "Epoch [1/15], Step [700/782], Loss: 2.3268\n",
      "Epoch [1/15], Step [720/782], Loss: 1.9232\n",
      "Epoch [1/15], Step [740/782], Loss: 2.1263\n",
      "Epoch [1/15], Step [760/782], Loss: 2.5103\n",
      "Epoch [1/15], Step [780/782], Loss: 2.3992\n",
      "\n",
      "train-loss: 0.0437, train-acc: 38.3200\n",
      "test loss: 0.0343, test acc: 46.0640\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 2\n",
      "\n",
      "Epoch [2/15], Step [0/782], Loss: 2.3181\n",
      "Epoch [2/15], Step [20/782], Loss: 1.8916\n",
      "Epoch [2/15], Step [40/782], Loss: 2.0218\n",
      "Epoch [2/15], Step [60/782], Loss: 2.1951\n",
      "Epoch [2/15], Step [80/782], Loss: 2.1220\n",
      "Epoch [2/15], Step [100/782], Loss: 2.2985\n",
      "Epoch [2/15], Step [120/782], Loss: 1.8260\n",
      "Epoch [2/15], Step [140/782], Loss: 1.9497\n",
      "Epoch [2/15], Step [160/782], Loss: 1.9881\n",
      "Epoch [2/15], Step [180/782], Loss: 2.0527\n",
      "Epoch [2/15], Step [200/782], Loss: 1.9126\n",
      "Epoch [2/15], Step [220/782], Loss: 2.2316\n",
      "Epoch [2/15], Step [240/782], Loss: 2.3880\n",
      "Epoch [2/15], Step [260/782], Loss: 2.1302\n",
      "Epoch [2/15], Step [280/782], Loss: 2.1511\n",
      "Epoch [2/15], Step [300/782], Loss: 2.4005\n",
      "Epoch [2/15], Step [320/782], Loss: 2.2045\n",
      "Epoch [2/15], Step [340/782], Loss: 1.9698\n",
      "Epoch [2/15], Step [360/782], Loss: 2.5104\n",
      "Epoch [2/15], Step [380/782], Loss: 2.1621\n",
      "Epoch [2/15], Step [400/782], Loss: 2.4095\n",
      "Epoch [2/15], Step [420/782], Loss: 1.8545\n",
      "Epoch [2/15], Step [440/782], Loss: 2.4215\n",
      "Epoch [2/15], Step [460/782], Loss: 2.3872\n",
      "Epoch [2/15], Step [480/782], Loss: 1.9688\n",
      "Epoch [2/15], Step [500/782], Loss: 1.8740\n",
      "Epoch [2/15], Step [520/782], Loss: 1.8311\n",
      "Epoch [2/15], Step [540/782], Loss: 2.3044\n",
      "Epoch [2/15], Step [560/782], Loss: 2.1595\n",
      "Epoch [2/15], Step [580/782], Loss: 2.0877\n",
      "Epoch [2/15], Step [600/782], Loss: 1.9136\n",
      "Epoch [2/15], Step [620/782], Loss: 2.5331\n",
      "Epoch [2/15], Step [640/782], Loss: 2.3150\n",
      "Epoch [2/15], Step [660/782], Loss: 1.7513\n",
      "Epoch [2/15], Step [680/782], Loss: 2.1731\n",
      "Epoch [2/15], Step [700/782], Loss: 1.8735\n",
      "Epoch [2/15], Step [720/782], Loss: 2.2932\n",
      "Epoch [2/15], Step [740/782], Loss: 2.4086\n",
      "Epoch [2/15], Step [760/782], Loss: 2.1986\n",
      "Epoch [2/15], Step [780/782], Loss: 2.1740\n",
      "\n",
      "train-loss: 0.0401, train-acc: 44.5840\n",
      "test loss: 0.0324, test acc: 50.6100\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 3\n",
      "\n",
      "Epoch [3/15], Step [0/782], Loss: 1.8195\n",
      "Epoch [3/15], Step [20/782], Loss: 1.7330\n",
      "Epoch [3/15], Step [40/782], Loss: 2.2281\n",
      "Epoch [3/15], Step [60/782], Loss: 1.7734\n",
      "Epoch [3/15], Step [80/782], Loss: 1.8021\n",
      "Epoch [3/15], Step [100/782], Loss: 1.7887\n",
      "Epoch [3/15], Step [120/782], Loss: 2.1440\n",
      "Epoch [3/15], Step [140/782], Loss: 1.6673\n",
      "Epoch [3/15], Step [160/782], Loss: 1.9548\n",
      "Epoch [3/15], Step [180/782], Loss: 1.8021\n",
      "Epoch [3/15], Step [200/782], Loss: 1.8202\n",
      "Epoch [3/15], Step [220/782], Loss: 2.0573\n",
      "Epoch [3/15], Step [240/782], Loss: 2.2808\n",
      "Epoch [3/15], Step [260/782], Loss: 1.7508\n",
      "Epoch [3/15], Step [280/782], Loss: 2.1908\n",
      "Epoch [3/15], Step [300/782], Loss: 1.9465\n",
      "Epoch [3/15], Step [320/782], Loss: 2.1144\n",
      "Epoch [3/15], Step [340/782], Loss: 1.5926\n",
      "Epoch [3/15], Step [360/782], Loss: 1.7606\n",
      "Epoch [3/15], Step [380/782], Loss: 2.0505\n",
      "Epoch [3/15], Step [400/782], Loss: 1.6792\n",
      "Epoch [3/15], Step [420/782], Loss: 1.7533\n",
      "Epoch [3/15], Step [440/782], Loss: 2.4216\n",
      "Epoch [3/15], Step [460/782], Loss: 1.9775\n",
      "Epoch [3/15], Step [480/782], Loss: 2.0505\n",
      "Epoch [3/15], Step [500/782], Loss: 1.8042\n",
      "Epoch [3/15], Step [520/782], Loss: 1.8605\n",
      "Epoch [3/15], Step [540/782], Loss: 2.0849\n",
      "Epoch [3/15], Step [560/782], Loss: 1.5682\n",
      "Epoch [3/15], Step [580/782], Loss: 2.1365\n",
      "Epoch [3/15], Step [600/782], Loss: 2.3246\n",
      "Epoch [3/15], Step [620/782], Loss: 2.3359\n",
      "Epoch [3/15], Step [640/782], Loss: 2.2016\n",
      "Epoch [3/15], Step [660/782], Loss: 2.1088\n",
      "Epoch [3/15], Step [680/782], Loss: 1.9757\n",
      "Epoch [3/15], Step [700/782], Loss: 1.8795\n",
      "Epoch [3/15], Step [720/782], Loss: 1.8614\n",
      "Epoch [3/15], Step [740/782], Loss: 1.8351\n",
      "Epoch [3/15], Step [760/782], Loss: 1.6255\n",
      "Epoch [3/15], Step [780/782], Loss: 1.5715\n",
      "\n",
      "train-loss: 0.0378, train-acc: 48.0560\n",
      "test loss: 0.0306, test acc: 55.2520\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 4\n",
      "\n",
      "Epoch [4/15], Step [0/782], Loss: 1.7525\n",
      "Epoch [4/15], Step [20/782], Loss: 1.7804\n",
      "Epoch [4/15], Step [40/782], Loss: 2.0712\n",
      "Epoch [4/15], Step [60/782], Loss: 1.5424\n",
      "Epoch [4/15], Step [80/782], Loss: 1.7299\n",
      "Epoch [4/15], Step [100/782], Loss: 1.8391\n",
      "Epoch [4/15], Step [120/782], Loss: 1.8979\n",
      "Epoch [4/15], Step [140/782], Loss: 1.7198\n",
      "Epoch [4/15], Step [160/782], Loss: 2.0276\n",
      "Epoch [4/15], Step [180/782], Loss: 1.8656\n",
      "Epoch [4/15], Step [200/782], Loss: 2.0172\n",
      "Epoch [4/15], Step [220/782], Loss: 1.6727\n",
      "Epoch [4/15], Step [240/782], Loss: 1.7049\n",
      "Epoch [4/15], Step [260/782], Loss: 1.6294\n",
      "Epoch [4/15], Step [280/782], Loss: 2.3464\n",
      "Epoch [4/15], Step [300/782], Loss: 2.0394\n",
      "Epoch [4/15], Step [320/782], Loss: 1.7834\n",
      "Epoch [4/15], Step [340/782], Loss: 1.7184\n",
      "Epoch [4/15], Step [360/782], Loss: 1.8974\n",
      "Epoch [4/15], Step [380/782], Loss: 1.9088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], Step [400/782], Loss: 1.8012\n",
      "Epoch [4/15], Step [420/782], Loss: 2.1234\n",
      "Epoch [4/15], Step [440/782], Loss: 2.0976\n",
      "Epoch [4/15], Step [460/782], Loss: 1.9962\n",
      "Epoch [4/15], Step [480/782], Loss: 2.1120\n",
      "Epoch [4/15], Step [500/782], Loss: 1.7949\n",
      "Epoch [4/15], Step [520/782], Loss: 1.9850\n",
      "Epoch [4/15], Step [540/782], Loss: 1.7502\n",
      "Epoch [4/15], Step [560/782], Loss: 2.1557\n",
      "Epoch [4/15], Step [580/782], Loss: 1.9549\n",
      "Epoch [4/15], Step [600/782], Loss: 1.7579\n",
      "Epoch [4/15], Step [620/782], Loss: 1.9120\n",
      "Epoch [4/15], Step [640/782], Loss: 1.7786\n",
      "Epoch [4/15], Step [660/782], Loss: 2.0907\n",
      "Epoch [4/15], Step [680/782], Loss: 2.2200\n",
      "Epoch [4/15], Step [700/782], Loss: 2.1458\n",
      "Epoch [4/15], Step [720/782], Loss: 2.1529\n",
      "Epoch [4/15], Step [740/782], Loss: 1.4499\n",
      "Epoch [4/15], Step [760/782], Loss: 1.6431\n",
      "Epoch [4/15], Step [780/782], Loss: 1.8070\n",
      "\n",
      "train-loss: 0.0360, train-acc: 50.9220\n",
      "test loss: 0.0291, test acc: 58.9320\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 5\n",
      "\n",
      "Epoch [5/15], Step [0/782], Loss: 1.4906\n",
      "Epoch [5/15], Step [20/782], Loss: 1.7295\n",
      "Epoch [5/15], Step [40/782], Loss: 1.8578\n",
      "Epoch [5/15], Step [60/782], Loss: 1.8042\n",
      "Epoch [5/15], Step [80/782], Loss: 1.3682\n",
      "Epoch [5/15], Step [100/782], Loss: 1.5593\n",
      "Epoch [5/15], Step [120/782], Loss: 1.1245\n",
      "Epoch [5/15], Step [140/782], Loss: 1.8289\n",
      "Epoch [5/15], Step [160/782], Loss: 1.5021\n",
      "Epoch [5/15], Step [180/782], Loss: 1.6774\n",
      "Epoch [5/15], Step [200/782], Loss: 2.0549\n",
      "Epoch [5/15], Step [220/782], Loss: 1.2198\n",
      "Epoch [5/15], Step [240/782], Loss: 1.9779\n",
      "Epoch [5/15], Step [260/782], Loss: 1.7027\n",
      "Epoch [5/15], Step [280/782], Loss: 1.9940\n",
      "Epoch [5/15], Step [300/782], Loss: 1.5571\n",
      "Epoch [5/15], Step [320/782], Loss: 1.7260\n",
      "Epoch [5/15], Step [340/782], Loss: 1.3985\n",
      "Epoch [5/15], Step [360/782], Loss: 2.1133\n",
      "Epoch [5/15], Step [380/782], Loss: 1.6572\n",
      "Epoch [5/15], Step [400/782], Loss: 1.5632\n",
      "Epoch [5/15], Step [420/782], Loss: 2.0649\n",
      "Epoch [5/15], Step [440/782], Loss: 1.4326\n",
      "Epoch [5/15], Step [460/782], Loss: 1.8240\n",
      "Epoch [5/15], Step [480/782], Loss: 1.7947\n",
      "Epoch [5/15], Step [500/782], Loss: 1.7793\n",
      "Epoch [5/15], Step [520/782], Loss: 1.4282\n",
      "Epoch [5/15], Step [540/782], Loss: 1.6259\n",
      "Epoch [5/15], Step [560/782], Loss: 1.6601\n",
      "Epoch [5/15], Step [580/782], Loss: 1.5078\n",
      "Epoch [5/15], Step [600/782], Loss: 1.4432\n",
      "Epoch [5/15], Step [620/782], Loss: 1.8718\n",
      "Epoch [5/15], Step [640/782], Loss: 1.3716\n",
      "Epoch [5/15], Step [660/782], Loss: 2.2397\n",
      "Epoch [5/15], Step [680/782], Loss: 1.7304\n",
      "Epoch [5/15], Step [700/782], Loss: 2.2059\n",
      "Epoch [5/15], Step [720/782], Loss: 1.5818\n",
      "Epoch [5/15], Step [740/782], Loss: 1.5411\n",
      "Epoch [5/15], Step [760/782], Loss: 1.1978\n",
      "Epoch [5/15], Step [780/782], Loss: 1.6607\n",
      "\n",
      "train-loss: 0.0344, train-acc: 53.8420\n",
      "test loss: 0.0278, test acc: 60.9800\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 6\n",
      "\n",
      "Epoch [6/15], Step [0/782], Loss: 1.5884\n",
      "Epoch [6/15], Step [20/782], Loss: 1.4716\n",
      "Epoch [6/15], Step [40/782], Loss: 1.3030\n",
      "Epoch [6/15], Step [60/782], Loss: 1.3652\n",
      "Epoch [6/15], Step [80/782], Loss: 1.7233\n",
      "Epoch [6/15], Step [100/782], Loss: 1.0807\n",
      "Epoch [6/15], Step [120/782], Loss: 1.6852\n",
      "Epoch [6/15], Step [140/782], Loss: 1.2431\n",
      "Epoch [6/15], Step [160/782], Loss: 1.7499\n",
      "Epoch [6/15], Step [180/782], Loss: 1.4453\n",
      "Epoch [6/15], Step [200/782], Loss: 2.0195\n",
      "Epoch [6/15], Step [220/782], Loss: 1.2559\n",
      "Epoch [6/15], Step [240/782], Loss: 1.5177\n",
      "Epoch [6/15], Step [260/782], Loss: 1.7941\n",
      "Epoch [6/15], Step [280/782], Loss: 1.7678\n",
      "Epoch [6/15], Step [300/782], Loss: 1.3409\n",
      "Epoch [6/15], Step [320/782], Loss: 2.0260\n",
      "Epoch [6/15], Step [340/782], Loss: 1.7894\n",
      "Epoch [6/15], Step [360/782], Loss: 1.3555\n",
      "Epoch [6/15], Step [380/782], Loss: 1.6942\n",
      "Epoch [6/15], Step [400/782], Loss: 1.8693\n",
      "Epoch [6/15], Step [420/782], Loss: 1.7505\n",
      "Epoch [6/15], Step [440/782], Loss: 1.6508\n",
      "Epoch [6/15], Step [460/782], Loss: 1.5259\n",
      "Epoch [6/15], Step [480/782], Loss: 1.7273\n",
      "Epoch [6/15], Step [500/782], Loss: 1.5472\n",
      "Epoch [6/15], Step [520/782], Loss: 1.7096\n",
      "Epoch [6/15], Step [540/782], Loss: 1.8064\n",
      "Epoch [6/15], Step [560/782], Loss: 2.3073\n",
      "Epoch [6/15], Step [580/782], Loss: 1.1601\n",
      "Epoch [6/15], Step [600/782], Loss: 1.6218\n",
      "Epoch [6/15], Step [620/782], Loss: 1.7779\n",
      "Epoch [6/15], Step [640/782], Loss: 2.0984\n",
      "Epoch [6/15], Step [660/782], Loss: 1.8085\n",
      "Epoch [6/15], Step [680/782], Loss: 1.5769\n",
      "Epoch [6/15], Step [700/782], Loss: 1.4915\n",
      "Epoch [6/15], Step [720/782], Loss: 1.5200\n",
      "Epoch [6/15], Step [740/782], Loss: 1.7556\n",
      "Epoch [6/15], Step [760/782], Loss: 1.8326\n",
      "Epoch [6/15], Step [780/782], Loss: 1.6624\n",
      "\n",
      "train-loss: 0.0331, train-acc: 56.6180\n",
      "test loss: 0.0269, test acc: 62.5620\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 7\n",
      "\n",
      "Epoch [7/15], Step [0/782], Loss: 1.3114\n",
      "Epoch [7/15], Step [20/782], Loss: 1.4840\n",
      "Epoch [7/15], Step [40/782], Loss: 1.1010\n",
      "Epoch [7/15], Step [60/782], Loss: 1.4766\n",
      "Epoch [7/15], Step [80/782], Loss: 1.6857\n",
      "Epoch [7/15], Step [100/782], Loss: 1.3314\n",
      "Epoch [7/15], Step [120/782], Loss: 1.4979\n",
      "Epoch [7/15], Step [140/782], Loss: 1.4986\n",
      "Epoch [7/15], Step [160/782], Loss: 1.6645\n",
      "Epoch [7/15], Step [180/782], Loss: 1.5169\n",
      "Epoch [7/15], Step [200/782], Loss: 0.9945\n",
      "Epoch [7/15], Step [220/782], Loss: 1.4804\n",
      "Epoch [7/15], Step [240/782], Loss: 1.6029\n",
      "Epoch [7/15], Step [260/782], Loss: 1.3502\n",
      "Epoch [7/15], Step [280/782], Loss: 1.9750\n",
      "Epoch [7/15], Step [300/782], Loss: 1.6467\n",
      "Epoch [7/15], Step [320/782], Loss: 1.4716\n",
      "Epoch [7/15], Step [340/782], Loss: 1.2852\n",
      "Epoch [7/15], Step [360/782], Loss: 1.8534\n",
      "Epoch [7/15], Step [380/782], Loss: 1.7702\n",
      "Epoch [7/15], Step [400/782], Loss: 1.4024\n",
      "Epoch [7/15], Step [420/782], Loss: 1.9243\n",
      "Epoch [7/15], Step [440/782], Loss: 1.3183\n",
      "Epoch [7/15], Step [460/782], Loss: 1.7734\n",
      "Epoch [7/15], Step [480/782], Loss: 1.4460\n",
      "Epoch [7/15], Step [500/782], Loss: 1.2810\n",
      "Epoch [7/15], Step [520/782], Loss: 1.4670\n",
      "Epoch [7/15], Step [540/782], Loss: 1.4691\n",
      "Epoch [7/15], Step [560/782], Loss: 2.0431\n",
      "Epoch [7/15], Step [580/782], Loss: 1.6180\n",
      "Epoch [7/15], Step [600/782], Loss: 1.4647\n",
      "Epoch [7/15], Step [620/782], Loss: 1.1864\n",
      "Epoch [7/15], Step [640/782], Loss: 1.7218\n",
      "Epoch [7/15], Step [660/782], Loss: 1.5884\n",
      "Epoch [7/15], Step [680/782], Loss: 1.7568\n",
      "Epoch [7/15], Step [700/782], Loss: 1.3799\n",
      "Epoch [7/15], Step [720/782], Loss: 1.3066\n",
      "Epoch [7/15], Step [740/782], Loss: 1.5276\n",
      "Epoch [7/15], Step [760/782], Loss: 1.9273\n",
      "Epoch [7/15], Step [780/782], Loss: 1.7043\n",
      "\n",
      "train-loss: 0.0320, train-acc: 58.3300\n",
      "test loss: 0.0259, test acc: 65.1040\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 8\n",
      "\n",
      "Epoch [8/15], Step [0/782], Loss: 1.2238\n",
      "Epoch [8/15], Step [20/782], Loss: 1.5636\n",
      "Epoch [8/15], Step [40/782], Loss: 1.2800\n",
      "Epoch [8/15], Step [60/782], Loss: 1.7866\n",
      "Epoch [8/15], Step [80/782], Loss: 1.1789\n",
      "Epoch [8/15], Step [100/782], Loss: 1.2776\n",
      "Epoch [8/15], Step [120/782], Loss: 1.7335\n",
      "Epoch [8/15], Step [140/782], Loss: 1.4124\n",
      "Epoch [8/15], Step [160/782], Loss: 1.4319\n",
      "Epoch [8/15], Step [180/782], Loss: 1.6140\n",
      "Epoch [8/15], Step [200/782], Loss: 1.1235\n",
      "Epoch [8/15], Step [220/782], Loss: 1.2337\n",
      "Epoch [8/15], Step [240/782], Loss: 1.2713\n",
      "Epoch [8/15], Step [260/782], Loss: 1.4449\n",
      "Epoch [8/15], Step [280/782], Loss: 1.3698\n",
      "Epoch [8/15], Step [300/782], Loss: 1.7276\n",
      "Epoch [8/15], Step [320/782], Loss: 1.3797\n",
      "Epoch [8/15], Step [340/782], Loss: 1.7043\n",
      "Epoch [8/15], Step [360/782], Loss: 1.5017\n",
      "Epoch [8/15], Step [380/782], Loss: 1.5548\n",
      "Epoch [8/15], Step [400/782], Loss: 1.4786\n",
      "Epoch [8/15], Step [420/782], Loss: 1.3482\n",
      "Epoch [8/15], Step [440/782], Loss: 1.2291\n",
      "Epoch [8/15], Step [460/782], Loss: 1.2997\n",
      "Epoch [8/15], Step [480/782], Loss: 1.4648\n",
      "Epoch [8/15], Step [500/782], Loss: 1.2860\n",
      "Epoch [8/15], Step [520/782], Loss: 1.3565\n",
      "Epoch [8/15], Step [540/782], Loss: 1.1604\n",
      "Epoch [8/15], Step [560/782], Loss: 1.8579\n",
      "Epoch [8/15], Step [580/782], Loss: 1.4740\n",
      "Epoch [8/15], Step [600/782], Loss: 1.4758\n",
      "Epoch [8/15], Step [620/782], Loss: 2.1916\n",
      "Epoch [8/15], Step [640/782], Loss: 1.3155\n",
      "Epoch [8/15], Step [660/782], Loss: 1.5872\n",
      "Epoch [8/15], Step [680/782], Loss: 1.1872\n",
      "Epoch [8/15], Step [700/782], Loss: 1.3135\n",
      "Epoch [8/15], Step [720/782], Loss: 1.6156\n",
      "Epoch [8/15], Step [740/782], Loss: 1.2560\n",
      "Epoch [8/15], Step [760/782], Loss: 1.4210\n",
      "Epoch [8/15], Step [780/782], Loss: 1.2908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-loss: 0.0310, train-acc: 59.8340\n",
      "test loss: 0.0251, test acc: 66.3020\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 9\n",
      "\n",
      "Epoch [9/15], Step [0/782], Loss: 1.2459\n",
      "Epoch [9/15], Step [20/782], Loss: 1.3318\n",
      "Epoch [9/15], Step [40/782], Loss: 1.1353\n",
      "Epoch [9/15], Step [60/782], Loss: 1.2067\n",
      "Epoch [9/15], Step [80/782], Loss: 1.0678\n",
      "Epoch [9/15], Step [100/782], Loss: 2.0701\n",
      "Epoch [9/15], Step [120/782], Loss: 1.3758\n",
      "Epoch [9/15], Step [140/782], Loss: 1.3212\n",
      "Epoch [9/15], Step [160/782], Loss: 1.4553\n",
      "Epoch [9/15], Step [180/782], Loss: 1.1758\n",
      "Epoch [9/15], Step [200/782], Loss: 1.4728\n",
      "Epoch [9/15], Step [220/782], Loss: 1.0573\n",
      "Epoch [9/15], Step [240/782], Loss: 1.5021\n",
      "Epoch [9/15], Step [260/782], Loss: 1.5964\n",
      "Epoch [9/15], Step [280/782], Loss: 1.1568\n",
      "Epoch [9/15], Step [300/782], Loss: 1.6284\n",
      "Epoch [9/15], Step [320/782], Loss: 1.6117\n",
      "Epoch [9/15], Step [340/782], Loss: 0.9425\n",
      "Epoch [9/15], Step [360/782], Loss: 1.5611\n",
      "Epoch [9/15], Step [380/782], Loss: 1.4316\n",
      "Epoch [9/15], Step [400/782], Loss: 1.4883\n",
      "Epoch [9/15], Step [420/782], Loss: 1.3110\n",
      "Epoch [9/15], Step [440/782], Loss: 1.6296\n",
      "Epoch [9/15], Step [460/782], Loss: 1.0876\n",
      "Epoch [9/15], Step [480/782], Loss: 1.7350\n",
      "Epoch [9/15], Step [500/782], Loss: 1.4807\n",
      "Epoch [9/15], Step [520/782], Loss: 1.5776\n",
      "Epoch [9/15], Step [540/782], Loss: 2.1814\n",
      "Epoch [9/15], Step [560/782], Loss: 1.2362\n",
      "Epoch [9/15], Step [580/782], Loss: 1.2915\n",
      "Epoch [9/15], Step [600/782], Loss: 1.5013\n",
      "Epoch [9/15], Step [620/782], Loss: 1.4941\n",
      "Epoch [9/15], Step [640/782], Loss: 1.2485\n",
      "Epoch [9/15], Step [660/782], Loss: 1.7476\n",
      "Epoch [9/15], Step [680/782], Loss: 1.3017\n",
      "Epoch [9/15], Step [700/782], Loss: 1.3432\n",
      "Epoch [9/15], Step [720/782], Loss: 1.4313\n",
      "Epoch [9/15], Step [740/782], Loss: 1.3999\n",
      "Epoch [9/15], Step [760/782], Loss: 1.0986\n",
      "Epoch [9/15], Step [780/782], Loss: 1.5729\n",
      "\n",
      "train-loss: 0.0301, train-acc: 61.4780\n",
      "test loss: 0.0243, test acc: 69.5140\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 10\n",
      "\n",
      "Epoch [10/15], Step [0/782], Loss: 1.7530\n",
      "Epoch [10/15], Step [20/782], Loss: 1.4732\n",
      "Epoch [10/15], Step [40/782], Loss: 1.3256\n",
      "Epoch [10/15], Step [60/782], Loss: 0.9829\n",
      "Epoch [10/15], Step [80/782], Loss: 1.0110\n",
      "Epoch [10/15], Step [100/782], Loss: 0.9885\n",
      "Epoch [10/15], Step [120/782], Loss: 1.1826\n",
      "Epoch [10/15], Step [140/782], Loss: 1.2056\n",
      "Epoch [10/15], Step [160/782], Loss: 1.1454\n",
      "Epoch [10/15], Step [180/782], Loss: 0.8489\n",
      "Epoch [10/15], Step [200/782], Loss: 0.8473\n",
      "Epoch [10/15], Step [220/782], Loss: 0.9649\n",
      "Epoch [10/15], Step [240/782], Loss: 0.8763\n",
      "Epoch [10/15], Step [260/782], Loss: 0.9463\n",
      "Epoch [10/15], Step [280/782], Loss: 0.9886\n",
      "Epoch [10/15], Step [300/782], Loss: 0.8416\n",
      "Epoch [10/15], Step [320/782], Loss: 0.8951\n",
      "Epoch [10/15], Step [340/782], Loss: 0.9358\n",
      "Epoch [10/15], Step [360/782], Loss: 0.9988\n",
      "Epoch [10/15], Step [380/782], Loss: 1.0333\n",
      "Epoch [10/15], Step [400/782], Loss: 0.7281\n",
      "Epoch [10/15], Step [420/782], Loss: 0.8802\n",
      "Epoch [10/15], Step [440/782], Loss: 0.9335\n",
      "Epoch [10/15], Step [460/782], Loss: 1.2367\n",
      "Epoch [10/15], Step [480/782], Loss: 0.5717\n",
      "Epoch [10/15], Step [500/782], Loss: 0.8022\n",
      "Epoch [10/15], Step [520/782], Loss: 1.1462\n",
      "Epoch [10/15], Step [540/782], Loss: 0.7596\n",
      "Epoch [10/15], Step [560/782], Loss: 1.1572\n",
      "Epoch [10/15], Step [580/782], Loss: 1.2037\n",
      "Epoch [10/15], Step [600/782], Loss: 0.8411\n",
      "Epoch [10/15], Step [620/782], Loss: 0.7997\n",
      "Epoch [10/15], Step [640/782], Loss: 1.0836\n",
      "Epoch [10/15], Step [660/782], Loss: 1.1421\n",
      "Epoch [10/15], Step [680/782], Loss: 0.7423\n",
      "Epoch [10/15], Step [700/782], Loss: 0.7179\n",
      "Epoch [10/15], Step [720/782], Loss: 0.8966\n",
      "Epoch [10/15], Step [740/782], Loss: 0.7890\n",
      "Epoch [10/15], Step [760/782], Loss: 0.7375\n",
      "Epoch [10/15], Step [780/782], Loss: 0.8088\n",
      "\n",
      "train-loss: 0.0287, train-acc: 73.4560\n",
      "test loss: 0.0229, test acc: 81.7380\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 11\n",
      "\n",
      "Epoch [11/15], Step [0/782], Loss: 0.6612\n",
      "Epoch [11/15], Step [20/782], Loss: 0.5107\n",
      "Epoch [11/15], Step [40/782], Loss: 0.9806\n",
      "Epoch [11/15], Step [60/782], Loss: 0.6386\n",
      "Epoch [11/15], Step [80/782], Loss: 0.6937\n",
      "Epoch [11/15], Step [100/782], Loss: 0.6837\n",
      "Epoch [11/15], Step [120/782], Loss: 0.8749\n",
      "Epoch [11/15], Step [140/782], Loss: 0.8948\n",
      "Epoch [11/15], Step [160/782], Loss: 0.5299\n",
      "Epoch [11/15], Step [180/782], Loss: 0.8684\n",
      "Epoch [11/15], Step [200/782], Loss: 0.6134\n",
      "Epoch [11/15], Step [220/782], Loss: 0.6641\n",
      "Epoch [11/15], Step [240/782], Loss: 0.5993\n",
      "Epoch [11/15], Step [260/782], Loss: 0.7307\n",
      "Epoch [11/15], Step [280/782], Loss: 0.9186\n",
      "Epoch [11/15], Step [300/782], Loss: 0.7399\n",
      "Epoch [11/15], Step [320/782], Loss: 0.5761\n",
      "Epoch [11/15], Step [340/782], Loss: 0.8183\n",
      "Epoch [11/15], Step [360/782], Loss: 0.6684\n",
      "Epoch [11/15], Step [380/782], Loss: 0.6341\n",
      "Epoch [11/15], Step [400/782], Loss: 0.6320\n",
      "Epoch [11/15], Step [420/782], Loss: 0.5375\n",
      "Epoch [11/15], Step [440/782], Loss: 0.5744\n",
      "Epoch [11/15], Step [460/782], Loss: 0.5284\n",
      "Epoch [11/15], Step [480/782], Loss: 1.2143\n",
      "Epoch [11/15], Step [500/782], Loss: 0.6049\n",
      "Epoch [11/15], Step [520/782], Loss: 0.8363\n",
      "Epoch [11/15], Step [540/782], Loss: 0.5874\n",
      "Epoch [11/15], Step [560/782], Loss: 0.9524\n",
      "Epoch [11/15], Step [580/782], Loss: 1.0033\n",
      "Epoch [11/15], Step [600/782], Loss: 0.7926\n",
      "Epoch [11/15], Step [620/782], Loss: 0.8141\n",
      "Epoch [11/15], Step [640/782], Loss: 0.7608\n",
      "Epoch [11/15], Step [660/782], Loss: 0.8520\n",
      "Epoch [11/15], Step [680/782], Loss: 0.6801\n",
      "Epoch [11/15], Step [700/782], Loss: 0.7087\n",
      "Epoch [11/15], Step [720/782], Loss: 0.5907\n",
      "Epoch [11/15], Step [740/782], Loss: 0.9056\n",
      "Epoch [11/15], Step [760/782], Loss: 0.6825\n",
      "Epoch [11/15], Step [780/782], Loss: 0.6321\n",
      "\n",
      "train-loss: 0.0273, train-acc: 78.0060\n",
      "test loss: 0.0217, test acc: 84.8260\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 12\n",
      "\n",
      "Epoch [12/15], Step [0/782], Loss: 0.6224\n",
      "Epoch [12/15], Step [20/782], Loss: 0.8089\n",
      "Epoch [12/15], Step [40/782], Loss: 0.7528\n",
      "Epoch [12/15], Step [60/782], Loss: 0.6559\n",
      "Epoch [12/15], Step [80/782], Loss: 0.6738\n",
      "Epoch [12/15], Step [100/782], Loss: 0.5789\n",
      "Epoch [12/15], Step [120/782], Loss: 0.6834\n",
      "Epoch [12/15], Step [140/782], Loss: 0.7184\n",
      "Epoch [12/15], Step [160/782], Loss: 0.7097\n",
      "Epoch [12/15], Step [180/782], Loss: 0.7968\n",
      "Epoch [12/15], Step [200/782], Loss: 0.8349\n",
      "Epoch [12/15], Step [220/782], Loss: 0.5066\n",
      "Epoch [12/15], Step [240/782], Loss: 0.5289\n",
      "Epoch [12/15], Step [260/782], Loss: 0.7800\n",
      "Epoch [12/15], Step [280/782], Loss: 0.7208\n",
      "Epoch [12/15], Step [300/782], Loss: 0.7060\n",
      "Epoch [12/15], Step [320/782], Loss: 0.8002\n",
      "Epoch [12/15], Step [340/782], Loss: 0.5128\n",
      "Epoch [12/15], Step [360/782], Loss: 0.3564\n",
      "Epoch [12/15], Step [380/782], Loss: 0.6879\n",
      "Epoch [12/15], Step [400/782], Loss: 0.3684\n",
      "Epoch [12/15], Step [420/782], Loss: 0.5647\n",
      "Epoch [12/15], Step [440/782], Loss: 0.6986\n",
      "Epoch [12/15], Step [460/782], Loss: 0.6397\n",
      "Epoch [12/15], Step [480/782], Loss: 0.5660\n",
      "Epoch [12/15], Step [500/782], Loss: 0.7602\n",
      "Epoch [12/15], Step [520/782], Loss: 0.6441\n",
      "Epoch [12/15], Step [540/782], Loss: 0.6162\n",
      "Epoch [12/15], Step [560/782], Loss: 0.7405\n",
      "Epoch [12/15], Step [580/782], Loss: 0.6364\n",
      "Epoch [12/15], Step [600/782], Loss: 0.8150\n",
      "Epoch [12/15], Step [620/782], Loss: 0.7700\n",
      "Epoch [12/15], Step [640/782], Loss: 0.8699\n",
      "Epoch [12/15], Step [660/782], Loss: 0.5465\n",
      "Epoch [12/15], Step [680/782], Loss: 0.7363\n",
      "Epoch [12/15], Step [700/782], Loss: 0.4335\n",
      "Epoch [12/15], Step [720/782], Loss: 0.5705\n",
      "Epoch [12/15], Step [740/782], Loss: 0.7617\n",
      "Epoch [12/15], Step [760/782], Loss: 0.7242\n",
      "Epoch [12/15], Step [780/782], Loss: 0.9378\n",
      "\n",
      "train-loss: 0.0260, train-acc: 80.5520\n",
      "test loss: 0.0205, test acc: 87.0540\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 13\n",
      "\n",
      "Epoch [13/15], Step [0/782], Loss: 0.6783\n",
      "Epoch [13/15], Step [20/782], Loss: 0.3983\n",
      "Epoch [13/15], Step [40/782], Loss: 0.7053\n",
      "Epoch [13/15], Step [60/782], Loss: 0.3492\n",
      "Epoch [13/15], Step [80/782], Loss: 0.3953\n",
      "Epoch [13/15], Step [100/782], Loss: 0.5053\n",
      "Epoch [13/15], Step [120/782], Loss: 0.7283\n",
      "Epoch [13/15], Step [140/782], Loss: 0.4672\n",
      "Epoch [13/15], Step [160/782], Loss: 0.5098\n",
      "Epoch [13/15], Step [180/782], Loss: 0.6255\n",
      "Epoch [13/15], Step [200/782], Loss: 0.5853\n",
      "Epoch [13/15], Step [220/782], Loss: 0.4707\n",
      "Epoch [13/15], Step [240/782], Loss: 0.6490\n",
      "Epoch [13/15], Step [260/782], Loss: 0.6302\n",
      "Epoch [13/15], Step [280/782], Loss: 0.6901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15], Step [300/782], Loss: 0.5018\n",
      "Epoch [13/15], Step [320/782], Loss: 0.3535\n",
      "Epoch [13/15], Step [340/782], Loss: 0.7694\n",
      "Epoch [13/15], Step [360/782], Loss: 0.4586\n",
      "Epoch [13/15], Step [380/782], Loss: 0.4926\n",
      "Epoch [13/15], Step [400/782], Loss: 0.5330\n",
      "Epoch [13/15], Step [420/782], Loss: 0.6189\n",
      "Epoch [13/15], Step [440/782], Loss: 0.3369\n",
      "Epoch [13/15], Step [460/782], Loss: 0.4647\n",
      "Epoch [13/15], Step [480/782], Loss: 0.6629\n",
      "Epoch [13/15], Step [500/782], Loss: 0.5346\n",
      "Epoch [13/15], Step [520/782], Loss: 0.7827\n",
      "Epoch [13/15], Step [540/782], Loss: 0.7456\n",
      "Epoch [13/15], Step [560/782], Loss: 1.0851\n",
      "Epoch [13/15], Step [580/782], Loss: 0.5747\n",
      "Epoch [13/15], Step [600/782], Loss: 0.4851\n",
      "Epoch [13/15], Step [620/782], Loss: 0.6487\n",
      "Epoch [13/15], Step [640/782], Loss: 0.4614\n",
      "Epoch [13/15], Step [660/782], Loss: 0.6393\n",
      "Epoch [13/15], Step [680/782], Loss: 0.5869\n",
      "Epoch [13/15], Step [700/782], Loss: 0.4120\n",
      "Epoch [13/15], Step [720/782], Loss: 0.4149\n",
      "Epoch [13/15], Step [740/782], Loss: 0.6284\n",
      "Epoch [13/15], Step [760/782], Loss: 0.5557\n",
      "Epoch [13/15], Step [780/782], Loss: 0.5662\n",
      "\n",
      "train-loss: 0.0248, train-acc: 82.5900\n",
      "test loss: 0.0194, test acc: 88.8100\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 14\n",
      "\n",
      "Epoch [14/15], Step [0/782], Loss: 0.6118\n",
      "Epoch [14/15], Step [20/782], Loss: 0.3704\n",
      "Epoch [14/15], Step [40/782], Loss: 0.5607\n",
      "Epoch [14/15], Step [60/782], Loss: 0.4469\n",
      "Epoch [14/15], Step [80/782], Loss: 0.6033\n",
      "Epoch [14/15], Step [100/782], Loss: 0.3480\n",
      "Epoch [14/15], Step [120/782], Loss: 0.6136\n",
      "Epoch [14/15], Step [140/782], Loss: 0.7365\n",
      "Epoch [14/15], Step [160/782], Loss: 0.4060\n",
      "Epoch [14/15], Step [180/782], Loss: 0.4982\n",
      "Epoch [14/15], Step [200/782], Loss: 0.7154\n",
      "Epoch [14/15], Step [220/782], Loss: 0.4518\n",
      "Epoch [14/15], Step [240/782], Loss: 0.4699\n",
      "Epoch [14/15], Step [260/782], Loss: 0.3878\n",
      "Epoch [14/15], Step [280/782], Loss: 0.5016\n",
      "Epoch [14/15], Step [300/782], Loss: 0.5907\n",
      "Epoch [14/15], Step [320/782], Loss: 0.4247\n",
      "Epoch [14/15], Step [340/782], Loss: 0.6203\n",
      "Epoch [14/15], Step [360/782], Loss: 0.3098\n",
      "Epoch [14/15], Step [380/782], Loss: 0.3179\n",
      "Epoch [14/15], Step [400/782], Loss: 0.3602\n",
      "Epoch [14/15], Step [420/782], Loss: 0.5243\n",
      "Epoch [14/15], Step [440/782], Loss: 0.4514\n",
      "Epoch [14/15], Step [460/782], Loss: 0.4763\n",
      "Epoch [14/15], Step [480/782], Loss: 0.5118\n",
      "Epoch [14/15], Step [500/782], Loss: 0.5555\n",
      "Epoch [14/15], Step [520/782], Loss: 0.7550\n",
      "Epoch [14/15], Step [540/782], Loss: 0.5603\n",
      "Epoch [14/15], Step [560/782], Loss: 0.4967\n",
      "Epoch [14/15], Step [580/782], Loss: 0.6666\n",
      "Epoch [14/15], Step [600/782], Loss: 0.4669\n",
      "Epoch [14/15], Step [620/782], Loss: 0.4937\n",
      "Epoch [14/15], Step [640/782], Loss: 0.3704\n",
      "Epoch [14/15], Step [660/782], Loss: 0.3909\n",
      "Epoch [14/15], Step [680/782], Loss: 0.3959\n",
      "Epoch [14/15], Step [700/782], Loss: 0.2569\n",
      "Epoch [14/15], Step [720/782], Loss: 0.2814\n",
      "Epoch [14/15], Step [740/782], Loss: 0.5753\n",
      "Epoch [14/15], Step [760/782], Loss: 0.3039\n",
      "Epoch [14/15], Step [780/782], Loss: 0.7393\n",
      "\n",
      "train-loss: 0.0236, train-acc: 84.6420\n",
      "test loss: 0.0185, test acc: 90.7340\n",
      "\n",
      "Improvement-Detected, save-model\n",
      "Epoch 15\n",
      "\n",
      "Epoch [15/15], Step [0/782], Loss: 0.1964\n",
      "Epoch [15/15], Step [20/782], Loss: 0.3543\n",
      "Epoch [15/15], Step [40/782], Loss: 0.3923\n",
      "Epoch [15/15], Step [60/782], Loss: 0.5855\n",
      "Epoch [15/15], Step [80/782], Loss: 0.5379\n",
      "Epoch [15/15], Step [100/782], Loss: 0.6972\n",
      "Epoch [15/15], Step [120/782], Loss: 0.3851\n",
      "Epoch [15/15], Step [140/782], Loss: 0.3170\n",
      "Epoch [15/15], Step [160/782], Loss: 0.4379\n",
      "Epoch [15/15], Step [180/782], Loss: 0.4619\n",
      "Epoch [15/15], Step [200/782], Loss: 0.4528\n",
      "Epoch [15/15], Step [220/782], Loss: 0.3852\n",
      "Epoch [15/15], Step [240/782], Loss: 0.3656\n",
      "Epoch [15/15], Step [260/782], Loss: 0.5111\n",
      "Epoch [15/15], Step [280/782], Loss: 0.4532\n",
      "Epoch [15/15], Step [300/782], Loss: 0.3114\n",
      "Epoch [15/15], Step [320/782], Loss: 0.4417\n",
      "Epoch [15/15], Step [340/782], Loss: 0.5123\n",
      "Epoch [15/15], Step [360/782], Loss: 0.5464\n",
      "Epoch [15/15], Step [380/782], Loss: 0.7257\n",
      "Epoch [15/15], Step [400/782], Loss: 0.5873\n",
      "Epoch [15/15], Step [420/782], Loss: 0.7518\n",
      "Epoch [15/15], Step [440/782], Loss: 0.3144\n",
      "Epoch [15/15], Step [460/782], Loss: 0.6366\n",
      "Epoch [15/15], Step [480/782], Loss: 0.6162\n",
      "Epoch [15/15], Step [500/782], Loss: 0.3032\n",
      "Epoch [15/15], Step [520/782], Loss: 0.3533\n",
      "Epoch [15/15], Step [540/782], Loss: 0.4088\n",
      "Epoch [15/15], Step [560/782], Loss: 0.3014\n",
      "Epoch [15/15], Step [580/782], Loss: 0.5102\n",
      "Epoch [15/15], Step [600/782], Loss: 0.4020\n",
      "Epoch [15/15], Step [620/782], Loss: 0.6185\n",
      "Epoch [15/15], Step [640/782], Loss: 0.2496\n",
      "Epoch [15/15], Step [660/782], Loss: 0.6205\n",
      "Epoch [15/15], Step [680/782], Loss: 0.4495\n",
      "Epoch [15/15], Step [700/782], Loss: 0.2613\n",
      "Epoch [15/15], Step [720/782], Loss: 0.6428\n",
      "Epoch [15/15], Step [740/782], Loss: 0.5320\n",
      "Epoch [15/15], Step [760/782], Loss: 0.5588\n",
      "Epoch [15/15], Step [780/782], Loss: 0.4144\n",
      "\n",
      "train-loss: 0.0226, train-acc: 86.1460\n",
      "test loss: 0.0176, test acc: 92.2540\n",
      "\n",
      "Improvement-Detected, save-model\n"
     ]
    }
   ],
   "source": [
    "#数据训练和检测\n",
    "train_acces, test_acces = [], []\n",
    "train_losses, test_losses = [], []\n",
    "total_step = len(dataloaders['train'])\n",
    "test_loss_min = np.Inf\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch}\\n')\n",
    "\n",
    "    network_learned = False\n",
    "\n",
    "    for phase in ['train', 'test']:\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "\n",
    "            for batch_idx, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "\n",
    "                if use_cuda:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "  \n",
    "                inputs = inputs.float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                if (batch_idx) % 20 == 0:\n",
    "                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch, num_epochs-1, batch_idx, total_step, loss.item()))\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    if use_cuda:\n",
    "                        inputs = Variable(inputs.cuda())\n",
    "                        labels = Variable(labels.cuda())\n",
    "                    else:\n",
    "                        inputs, labels = Variable(inputs), Variable(labels)\n",
    "                    \n",
    "                    inputs = inputs.float()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    running_loss += loss.item()\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "            network_learned = running_loss < test_loss_min\n",
    "            test_loss_min = running_loss if network_learned else test_loss_min\n",
    "\n",
    "\n",
    "        epoch_loss = running_loss / len(data_sets[phase])\n",
    "        epoch_acc = running_corrects.double() / len(data_sets[phase])\n",
    "        \n",
    "        if phase == 'train':\n",
    "            train_acces.append(epoch_acc * 100)\n",
    "            train_losses.append(epoch_loss)\n",
    "        else:\n",
    "            test_acces.append(epoch_acc * 100)\n",
    "            test_losses.append(epoch_loss)\n",
    "    print(f'\\ntrain-loss: {np.mean(train_losses):.4f}, train-acc: {train_acces[-1]:.4f}')\n",
    "    print(f'test loss: {np.mean(test_losses):.4f}, test acc: {test_acces[-1]:.4f}\\n')\n",
    "\n",
    "    if network_learned:\n",
    "        torch.save(model.state_dict(), './models/weights.h5')\n",
    "        print('Improvement-Detected, save-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Train-Test Accuracy\")\n",
    "plt.plot(train_acces, label='Training acc')\n",
    "plt.plot(test_acces, label='Test acc')\n",
    "plt.xlabel('num_epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Train-Test Loss\")\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Test loss')\n",
    "plt.xlabel('num_epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
